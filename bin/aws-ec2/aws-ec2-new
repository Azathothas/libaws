#!/usr/bin/env python3
import traceback
import sys
import datetime
import util.exceptions
import util.strings
import util.iter
import util.dicts
import util.date
import util.colors
import random
import time
import pprint
import copy
import requests
import re
import util.colors
import os
import argh
import shell as sh
import aws
import aws.ec2
from aws import stderr

_default_init = 'date > /tmp/cloudinit.log'

_nvme_init = """
# pick the first nvme drive which is NOT mounted as / and prepare that as /mnt
set -x
while true; do
    echo 'wait for /dev/nvme*'
    if sudo fdisk -l | grep /dev/nvme &>/dev/null; then
        break
    fi
    sleep 1
done
disk=$(sudo fdisk -l | grep ^Disk | grep nvme | awk '{print $2}' | tr -d : | sort -u | grep -v $(df / | grep /dev | awk '{print $1}' | head -c11) | head -n1)
(
 echo g # Create a new empty GPT partition table
 echo n # Add a new partition
 echo 1 # Partition number
 echo   # First sector (Accept default: 1)
 echo   # Last sector (Accept default: varies)
 echo w # Write changes
) | sudo fdisk $disk
sleep 5
yes | sudo mkfs -t ext4 %(inodes)s ${disk}p1
sudo mkdir -p /mnt
sudo mount -o discard,noatime ${disk}p1 /mnt
sudo chown -R $(whoami):$(whoami) /mnt
echo ${disk}p1 /mnt ext4 discard,noatime 0 1 | sudo tee -a /etc/fstab
set +x
"""

_timeout_init = """
echo '# timeout will call this script before it `sudo poweroff`s, and wait 60 seconds for this script to complete' >> /tmp/timeout.sh
echo '
    warning="seconds remaining until timeout poweroff. tail -f /var/log/timeout.log to follow, increase /tmp/timeout.seconds to delay, or kill timeout.poweroff.sh to cancel."
    echo {} > /tmp/timeout.seconds
    # count down until timeout
    start=$(date +%s)
    while true; do
        now=$(date +%s)
        duration=$(($now - $start))
        timeout=$(cat /tmp/timeout.seconds)
        (($duration > $timeout)) && break
        remaining=$(($timeout - $duration))
        (($remaining <= 300)) && (($remaining % 60 == 0)) && wall "$remaining $warning"
        echo uptime seconds: $duration | sudo tee /var/log/timeout.log
        echo poweroff in seconds: $remaining | sudo tee -a /var/log/timeout.log
        sleep 5
    done
    # run timeout script and wait 60 seconds
    echo run: bash /tmp/timeout.sh > /var/log/timeout.log
    bash /tmp/timeout.sh &
    pid=$!
    start=$(date +%s)
    overtime=60
    while true; do
        ps $pid || break
        now=$(date +%s)
        duration=$(($now - $start))
        (($duration > $overtime)) && break
        remaining=$(($overtime - $duration))
        echo seconds until poweroff: $remaining > /var/log/timeout.log
        sleep 1
    done
    sudo poweroff
' > /tmp/timeout.poweroff.sh
bash /tmp/timeout.poweroff.sh &> /dev/null </dev/null &
disown %1
"""

ubuntus = {'bionic', 'xenial', 'trusty', 'eoan', 'focal'}
ubuntus_hvm_ssd = {'focal':  'ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server',
                   'eoan':   'ubuntu/images/hvm-ssd/ubuntu-eoan-19.10-amd64-server',
                   'bionic': 'ubuntu/images/hvm-ssd/ubuntu-bionic-18.04-amd64-server',
                   'xenial': 'ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server',
                   'trusty': 'ubuntu/images/hvm-ssd/ubuntu-trusty-14.04-amd64-server'}
ubuntus_pv = {'xenial': 'ubuntu/images/ebs-ssd/ubuntu-xenial-16.04-amd64-server',
              'trusty': 'ubuntu/images/ebs-ssd/ubuntu-trusty-14.04-amd64-server'}

def _ami_lambda():
    stderr('fetching latest lambda ami')
    resp = requests.get('https://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html')
    assert resp.status_code == 200
    ami = re.findall(r'(amzn-ami-hvm[^ ]+)"', resp.text)[0]
    amis = list(aws.resource('ec2').images.filter(Filters=[{'Name': 'name', 'Values': [ami]}]))
    assert len(amis) == 1
    ami_id = amis[0].image_id
    stderr('using ami', ami, ami_id)
    return ami_id

def _ami_ubuntu(name_fragment):
    filters = [{'Name': 'name', 'Values': [f'*{name_fragment}*']},
               {'Name': 'architecture', 'Values': ['x86_64']}]
    amis = list(aws.retry(aws.resource('ec2').images.filter)(Owners=['099720109477'], Filters=filters))
    amis = sorted(amis, key=lambda x: x.creation_date)
    return amis[-1].id

def _ami_amzn():
    filters = [{'Name': 'name', 'Values': ['amzn2-ami-hvm-2.0*-ebs']},
               {'Name': 'architecture', 'Values': ['x86_64']}]
    amis = list(aws.retry(aws.resource('ec2').images.filter)(Owners=['137112412989'], Filters=filters))
    amis = sorted(amis, key=lambda x: x.creation_date)
    stderr('using ami', amis[-1].name, amis[-1].id)
    return amis[-1].id

def _ami_arch():
    filters = [{'Name': 'name', 'Values': ['arch-linux-hvm-*-ebs']},
               {'Name': 'architecture', 'Values': ['x86_64']}]
    amis = list(aws.retry(aws.resource('ec2').images.filter)(Owners=['093273469852'], Filters=filters))
    amis = sorted(amis, key=lambda x: x.creation_date)
    stderr('using ami', amis[-1].name, amis[-1].id)
    return amis[-1].id

def _ami_deeplearning():
    filters = [{'Name': 'name', 'Values': ['Deep Learning AMI (Ubuntu)*']},
               {'Name': 'architecture', 'Values': ['x86_64']}]
    amis = list(aws.retry(aws.resource('ec2').images.filter)(Owners=[], Filters=filters))
    amis = sorted(amis, key=lambda x: x.creation_date)
    stderr('using ubuntu ami', amis[-1].name, amis[-1].id)
    return amis[-1].id

def _blocks(gigs, naming='sda', kms_id=None, iops=None, throughput=None):
    assert naming in ['sda', 'xvda'] # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/device_naming.html
    blocks = [{'DeviceName': ('/dev/sda1' if naming == 'sda' else '/dev/xvda'),
               'Ebs': {'VolumeSize': int(gigs),
                       'VolumeType': 'gp3',
                       'Iops': iops,
                       'Throughput': throughput,
                       'Encrypted': True,
                       'DeleteOnTermination': True}}]
    if kms_id:
        blocks[0]['Ebs']['KmsKeyId'] = kms_id
    return blocks

@aws.retry
def _sgs(names=None):
    sgs = list(aws.resource('ec2').security_groups.all())
    if names:
        sgs = [x
               for x in sgs
               if x.group_name in names
               or x.group_id in names]
    return sgs

def _make_spot_opts(spot, opts, fleet_role, vpc):
    if 'arn' not in fleet_role:
        err = aws.client('iam').exceptions.NoSuchEntityException
        try:
            fleet_role = aws.retry(aws.client('iam').get_role, err)(RoleName=fleet_role)['Role']['Arn']
        except err:
            assert False, util.colors.red(f'no such iam role {fleet_role}. specify a different one with `--fleet-role` or create defaults with `aws-iam-ensure-common-roles`')
    spot_opts = {}
    spot_opts['AllocationStrategy'] = 'lowestPrice'
    spot_opts['Type'] = 'request'
    spot_opts['ReplaceUnhealthyInstances'] = False
    spot_opts['InstanceInterruptionBehavior'] = 'terminate'
    spot_opts['TerminateInstancesWithExpiration'] = False
    spot_opts['SpotPrice'] = str(float(spot))
    spot_opts['IamFleetRole'] = fleet_role
    spot_opts['TargetCapacity'] = opts['MaxCount']
    opts['SecurityGroups'] = [{'GroupId': x} for x in opts['SecurityGroupIds']]
    opts = util.dicts.drop(opts, ['MaxCount', 'MinCount', 'SecurityGroupIds'])
    for tags in opts['TagSpecifications'].copy():
        if tags['ResourceType'] == 'volume':
            opts['TagSpecifications'].remove(tags) # volume tagging not supported with RequestSpotFleet
    if 'UserData' in opts:
        opts['UserData'] = util.strings.b64_encode(opts['UserData'])
    if 'SubnetId' in opts:
        spot_opts['LaunchSpecifications'] = [opts]
    else:
        spot_opts['LaunchSpecifications'] = []
        for zone in aws.zones():
            _opts = copy.deepcopy(opts)
            _opts['SubnetId'] = aws.ec2.subnet(vpc, zone)
            spot_opts['LaunchSpecifications'].append(_opts)
    # log the spot opts minus userdata and after combining subnets
    _spot_opts = copy.deepcopy(spot_opts)
    subnets = [opt['SubnetId'] for opt in _spot_opts['LaunchSpecifications']]
    _spot_opts['LaunchSpecifications'] = [_spot_opts['LaunchSpecifications'][0]]
    _spot_opts['LaunchSpecifications'][0]['SubnetId'] = subnets
    for spec in _spot_opts['LaunchSpecifications']:
        spec.pop('UserData', None)
    stderr('request spot instances:\n' + pprint.pformat(_spot_opts))
    # return spot opts
    return spot_opts

def _tear_down_spot_instances(request_id):
    aws.client('ec2').cancel_spot_fleet_requests(SpotFleetRequestIds=[request_id], TerminateInstances=True)
    stderr('cancelled spot fleet request:', request_id)
    xs = aws.client('ec2').describe_spot_fleet_instances(SpotFleetRequestId=request_id)['ActiveInstances']
    xs = [x.get('InstanceId') for x in xs]
    xs = [x for x in xs if x]
    if xs:
        sh.run('aws-ec2-wait-for-state -y', *xs, stream=True)
        sh.run('aws-ec2-rm -y', *xs, stream=True)

def _spot_errors(request_id):
    request_id = 'sfr-71797965-2d8c-4521-978e-7b0d82fe6228'
    date = aws.retry(aws.client('ec2').describe_spot_fleet_requests)(SpotFleetRequestIds=[request_id])['SpotFleetRequestConfigs'][0]['CreateTime']
    start = datetime.datetime(date.year, date.month, date.day)
    val = ''
    for record in aws.retry(aws.client('ec2').describe_spot_fleet_request_history)(SpotFleetRequestId=request_id, EventType='error', StartTime=start)['HistoryRecords']:
        val += record['EventInformation']['EventDescription'] + '\n\n'
    return val

def _create_spot_instances(**opts):
    request_id = aws.client('ec2').request_spot_fleet(SpotFleetRequestConfig=opts)['SpotFleetRequestId']
    stderr("wait for spot request to be filled for fleet:", request_id)
    try:
        for _ in range(300):
            resp = aws.retry(aws.client('ec2').describe_spot_fleet_requests)(SpotFleetRequestIds=[request_id])['SpotFleetRequestConfigs'][0]
            state = resp['SpotFleetRequestState']
            failed_states = ['cancelled', 'failed', 'cancelled_running', 'cancelled_terminating']
            assert state not in failed_states, 'spot fleet failed with: %s' % state
            assert resp.get('ActivityStatus') != 'error', f'spot fleet failed with errors:\n\n{_spot_errors(request_id)}'
            xs = aws.retry(aws.client('ec2').describe_spot_fleet_instances)(SpotFleetRequestId=request_id)['ActiveInstances']
            if len(xs) == opts['TargetCapacity']:
                break
            else:
                current = len(xs)
                stderr('waiting for requests:', opts['TargetCapacity'] - current)
                time.sleep(4 + random.random())
        else:
            raise AssertionError('failed to wait for spot requests')
    except:
        _tear_down_spot_instances(request_id)
        raise
    else:
        instance_ids = [x['InstanceId'] for x in xs]
        for _ in range(5):
            instances = aws.ec2.ls(instance_ids, None)
            if len(instances) == len(instance_ids):
                return instances
            time.sleep(5)
        raise Exception('failed to get the right number of instances')

@argh.arg('-t', '--type')
@argh.arg('-s', '--spot')
@argh.arg('-i', '--init')
@argh.arg('-k', '--key')
@argh.arg('-n', '--num')
def main(name: 'name of the instance', # type: ignore
         *tags: 'tags to set as "<key>=<value>"', # type: ignore
         key: 'key pair name'                          = os.environ.get('AWS_EC2_KEY'), # type: ignore
         ami: 'ami id'                                 = os.environ.get('AWS_EC2_AMI'), # type: ignore
         sg: 'security group name'                     = os.environ.get('AWS_EC2_SG'), # type: ignore
         type: 'instance type'                         = os.environ.get('AWS_EC2_TYPE'), # type: ignore
         vpc: 'vpc name'                               = os.environ.get('AWS_EC2_VPC'), # type: ignore
         kms_key_id: 'custom kms key for ebs'          = None, # type: ignore
         subnet: 'subnet id'                           = None, # type: ignore
         profile: 'iam instance profile'               = None, # type: ignore
         fleet_role: 'spot fleet iam role'             = 'aws-ec2-spot-fleet-tagging-role', # type: ignore
         zone: 'availability zone'                     = None, # type: ignore
         gigs: 'gb capacity of primary gp3 disk'       = 16, # type: ignore
         iops: 'gp3 disk iops'                         = 3000, # type: ignore
         throughput: 'gp3 disk throughput'             = 125, # type: ignore
         bytes_per_inode: 'instance store inode ratio' = 2048, # type: ignore
         init: 'run some bash via cloud init'          = _default_init, # type: ignore
         cmd: 'ssh command'                            = None, # type: ignore
         num: 'number of instances'                    = 1, # type: ignore
         spot_days: 'num days for spot price check'    = 2, # type: ignore
         no_wait: 'do not wait for ssh'                = False, # type: ignore
         login: 'login in to the instance'             = False, # type: ignore
         ec2_ssh_user: ( # type: ignore
             'what ssh user to use for this instance. '
             'this is ami specific, if not provided '
             'will try to guess based on ami choice, '
             'finally defaulting to "ubuntu".')        = None,
         verbatim_init: ( # type: ignore
             'use this string verbatim as the '
             'cloud-init user data.')                  = None,
         spot: ( # type: ignore
             'spot bid as percentage of the '
             'on-demand price for current type. '
             'check prices with `ec2 prices -h`. '
             'a value of 1.0, the default, bids '
             'at the on-demand price, so only get '
             'terminated if spot market rises above '
             'on-demand market. set to 0 use '
             'on-demand instead of spot.')             = float(os.environ.get('AWS_EC2_SPOT', 0.0)),
         seconds_timeout: ( # type: ignore
             'will `sudo poweroff` after this many '
             'seconds. calls `bash /tmp/timeout.sh` '
             'if it exists and waits 60 seconds for '
             'it to exit before calling `sudo poweroff`. '
             'set to 0 to disable. note: instance '
             'reboot clears this timeout.')            = int(os.environ.get('AWS_EC2_TIMEOUT', 0)),
         seconds_wait: ( # type: ignore
             'how many seconds to wait for ssh '
             'before continuing with however '
             'many instances became available '
             'and terminating the rest. set to 0 '
             ' to disable.           ')               = 0):
    assert key, '--key must be provided'
    assert ami, '--ami must be provided'
    assert sg, '--sg must be provided'
    assert type, '--type must be provided'
    assert vpc, '--vpc must be provided'
    if spot:
        spot_percentage = spot
        ondemand_price = sh.run('aws-ec2-prices -i', type)
        spot = float(spot) * float(ondemand_price)
        stderr(f'bidding spot at: (spot * on-demand) {spot_percentage} * {ondemand_price} = {spot}')
    num = int(num)
    assert not (spot and type == 't2.nano'), 'no spot pricing for t2.nano'
    assert not login or num == 1, util.colors.red('you asked to login, but you are starting more than one instance, so its not gonna happen')
    owner = sh.run('whoami')
    for tag in tags:
        assert '=' in tag, 'bad tag, should be key=value, not: %s' % tag
    ami_tags = {}
    ami_name = ami
    if ami_name == 'lambda':
        ami = _ami_lambda()
    elif ami_name == 'deeplearning':
        ami = _ami_deeplearning()
    elif ami_name == 'arch':
        ami = _ami_arch()
    elif ami_name == 'amzn':
        ami = _ami_amzn()
    elif ami in ubuntus:
        stderr('fetch latest ami for:', ami)
        distro = ami
        images = ubuntus_pv if type.split('.')[0] in ['t1', 'm1'] else ubuntus_hvm_ssd
        ami = _ami_ubuntu(images[distro])
    elif ami.startswith('ami-'):
        ami = ami.strip()
        stderr('using ami:', ami)
    else:
        ami, date, description, ami_tags_text = sh.run('aws-ec2-amis -m', ami_name).split()
        ami_tags = {k: v
                    for ami_tag in ami_tags_text.split(',')
                    for k, v in [ami_tag.split('=')]}
        stderr('using most recent ami for name:', ami_name, ami)
    if ec2_ssh_user:
        user = ec2_ssh_user
    elif 'user' in ami_tags:
        user = ami_tags['user']
    elif ami_name in {'lambda', 'amzn'}:
        user = 'user'
    elif ami_name == 'arch':
        user = 'arch'
    else:
        user = 'ubuntu'
    stderr('user:', user)
    if verbatim_init:
        init = verbatim_init
    else:
        if type.split('.')[0] in ['i3', 'i3en', 'c5d', 'm5d', 'r5d', 'z1d']:
            init = _nvme_init % {'inodes': f'-i {bytes_per_inode}'} + init
        if os.path.isfile(init):
            stderr('loading init script from file:', init)
            with open(init) as f:
                init = f.read()
            if init.startswith('#!'):
                assert init.startswith('#!/bin/bash'), f'bad init script: {init[:50]}...'
                init = '\n'.join(init.split('\n')[1:])
        if seconds_timeout:
            stderr(f'this instance will `sudo poweroff` after {seconds_timeout} seconds, or {round(int(seconds_timeout) / 60. / 60., 1)} hours, because of --seconds-timeout')
            init = _timeout_init.format(seconds_timeout) + init
        assert not init.startswith('#!'), 'init commands are bash snippets, and should not include a hashbang'
        init = '#!/bin/bash\npath=/tmp/$(uuidgen); echo %s | base64 -d > $path; sudo -u %s bash -e $path 2>&1' % (util.strings.b64_encode(init), user)
    opts = {}
    opts['UserData'] = init
    opts['ImageId'] = ami
    opts['MinCount'] = num
    opts['MaxCount'] = num
    opts['KeyName'] = key
    opts['SecurityGroupIds'] = [x.id for x in _sgs(names=[sg])]
    opts['InstanceType'] = type
    opts['BlockDeviceMappings'] = _blocks(gigs, 'xvda' if user == 'ec2-user' else 'sda', kms_key_id, iops, throughput)
    opts['TagSpecifications'] = [{'ResourceType': resource,
                                  'Tags': [{'Key': 'Name', 'Value': name},
                                           {'Key': 'owner', 'Value': owner},
                                           {'Key': 'user', 'Value': user},
                                           {'Key': 'creation-date', 'Value': aws.now()},
                                           {'Key': 'num', 'Value': str(num)}] + [{'Key': k, 'Value': v}
                                                                                 for tag in tags
                                                                                 for k, v in [tag.split('=')]]}
                                 for resource in ['instance', 'volume']]
    if profile:
        opts['IamInstanceProfile'] = {'Name': profile}
    _start = time.time()
    for _ in range(5):
        assert vpc or subnet, 'need to provide a --vpc or --subnet'
        # explicit subnet
        if subnet:
            opts['SubnetId'] = subnet
        # explicit zone
        elif zone:
            opts['SubnetId'] = aws.ec2.subnet(vpc, zone)
        # random subnet for on-deman
        elif not spot:
            zone = sh.run('aws-ec2-cheapest-zone', type, '-d', spot_days)
            opts['SubnetId'] = aws.ec2.subnet(vpc, zone)
        # spot fleets will place in all zones by default, see _make_spot_opts()
        else:
            pass
        stderr('using vpc:', vpc)
        if spot:
            spot_opts = _make_spot_opts(spot, opts, fleet_role, vpc)
            try:
                instances = _create_spot_instances(**spot_opts)
            except KeyboardInterrupt:
                raise
            except AssertionError:
                stderr()
                sys.exit(1)
            except Exception as e:
                if isinstance(e, aws.client('ec2').exceptions.ClientError) and e.response.get('Error', {}).get('Code') == 'InvalidSpotFleetRequestId.NotFound':
                    stderr('there is an error with the spot request, check the aws console')
                    sys.exit(1)
                else:
                    stderr(traceback.format_exc())
                    stderr('failed to create spot instances, retrying...')
                    continue
        else:
            stderr('create instances:\n' + pprint.pformat(util.dicts.drop(opts, ['UserData'])))
            instances = aws.resource('ec2').create_instances(**opts)
        ids = [i.instance_id for i in instances]
        if no_wait:
            stderr('instances:')
            return [i.instance_id for i in instances]
        else:
            stderr('instances:\n' + '\n'.join(ids))
            try:
                ready_ids = sh.run('aws-ec2-wait-for-ssh -ys', seconds_wait, *ids, stream=True).splitlines()
                break
            except KeyboardInterrupt:
                with util.exceptions.ignore():
                    sh.run('aws-ec2-rm -y', *ids, stream=True)
                raise
            except:
                with util.exceptions.ignore():
                    sh.run('aws-ec2-rm -y', *ids, stream=True)
                stderr('failed to spinup and then wait for ssh on instances, retrying...')
    else:
        assert False, 'failed to spinup and then wait for ssh on instances after 5 tries. aborting.'
    stderr(f'instance instantiation took {int(time.time() - _start)} seconds')
    ready_instances = aws.ec2.ls(ready_ids, 'running')
    if login:
        stderr('logging in...')
        sh.call('aws-ec2-ssh -yq', ready_instances[0].instance_id)
    elif cmd:
        if os.path.exists(cmd):
            stderr('reading cmd from:', os.path.abspath(cmd))
            with open(cmd) as f:
                cmd = f.read()
        stderr('running cmd...')
        sh.run('aws-ec2-ssh', *[i.instance_id for i in ready_instances], '--no-tty -yc -', stdin=cmd, stream=True)
    stderr('done')
    return [i.instance_id for i in ready_instances]

if __name__ == '__main__':
    with aws.setup():
        argh.dispatch_command(main)
